---
title: 如何保证Kafka的可靠性
date: 2022-05-21 23:47:03
permalink: /pages/76a94c/
categories:
  - 中间件
  - Kafka
tags:
  - 
---
# 可靠性保证
**kafka在哪些方面做出保证呢？**

 - 单生产者，kafka可以保证顺序消费
 - 只有当写入的消息被写入所有的副本时，才认为是“已提交”的
 - 只要有一个活跃的分区副本，那么，已提交的数据就不会丢失。
 - 消费者只能读取已经提交的消息

**如何保证topic元数据信息安全**
replication.factor配置topic的复制系数

**所有的分区副本都没有正常同步，分区首领又挂掉了，如何做选举？**
方案有两个

 - 在未正常同步的副中选举一个作为首领，缺点是存在丢失数据的风险。
 - 等待旧的首领恢复。缺点是可用性低。

配置unclean.leader.election.enable=true表示允许不同步的副本称为首领，这也将面临丢失消息的风险。
# producer如何做可靠性保证
**如何保证可靠投递消息？**

 1. ack=all表示broker要等待所有分区副本同步完消息才返回给producer response，是最可靠的投递。
 2. 设置重试次数，注意要做业务幂等。
 3. 有些小时不可重试错误，比如消息太大、认证错误等。根据业务来特殊处理这类消息。

# consumer如何做可靠性保证
**consumer请求的offset在broker上不存在时怎么处理？**
配置auto.offset.reset指定了两种策略：

 - earliest:从分区的开始读取
 - latest：从分区的末尾读取

